{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import json \n",
    "import numpy as np \n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import shapely\n",
    "import shapely.wkt\n",
    "from shapely import Point, Polygon\n",
    "\n",
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete dataset building for training data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab the buildings identified within each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = \"train/labels/\"\n",
    "training_labels = os.listdir(dir_path)\n",
    "sample = training_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_building_dataset(dir_path, data_labels): \n",
    "\n",
    "    df = pd.DataFrame(columns = ['image_name', 'classification', 'uid', 'polygon'])\n",
    "    for path in tqdm(data_labels): \n",
    "        d = pd.read_json(dir_path + path)\n",
    "        # look to see if a feature is identified in this image \n",
    "        ll = d['features']['xy']\n",
    "        if len(ll) > 0: \n",
    "            # look to see if any of these features are buildings \n",
    "            for i in range(0, len(ll)): \n",
    "                if ll[i]['properties']['feature_type'] == 'building' and 'subtype' in ll[i]['properties'].keys(): \n",
    "                    add = {'image_name': path, 'classification': ll[i]['properties']['subtype'], 'uid': ll[i]['properties']['uid'], 'polygon': ll[i]['wkt']}\n",
    "                    df.loc[len(df.index)] = add\n",
    "                    \n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5598/5598 [11:59<00:00,  7.79it/s]\n"
     ]
    }
   ],
   "source": [
    "df = find_building_dataset(dir_path, sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no-damage        117426\n",
       "minor-damage      14980\n",
       "major-damage      14161\n",
       "destroyed         13227\n",
       "un-classified      2993\n",
       "Name: classification, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['classification'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>classification</th>\n",
       "      <th>uid</th>\n",
       "      <th>polygon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>midwest-flooding_00000308_post_disaster.json</td>\n",
       "      <td>no-damage</td>\n",
       "      <td>3350c4e6-e7dc-4313-8b23-59233a6e2078</td>\n",
       "      <td>POLYGON ((319.9690811897951 118.8051167728774,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>midwest-flooding_00000308_post_disaster.json</td>\n",
       "      <td>no-damage</td>\n",
       "      <td>4ac81fae-312a-4050-bd41-92f677311b09</td>\n",
       "      <td>POLYGON ((448.3688195265795 92.6786134661785, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>midwest-flooding_00000308_post_disaster.json</td>\n",
       "      <td>no-damage</td>\n",
       "      <td>bcfa6989-a2b4-4aa6-a1f9-6adc62301b6c</td>\n",
       "      <td>POLYGON ((862.4316509232316 13.3651563899852, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>midwest-flooding_00000308_post_disaster.json</td>\n",
       "      <td>no-damage</td>\n",
       "      <td>497560fe-6da5-4826-a443-cd76fa4f2f86</td>\n",
       "      <td>POLYGON ((898.5940151494626 38.91158143295991,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>midwest-flooding_00000308_post_disaster.json</td>\n",
       "      <td>no-damage</td>\n",
       "      <td>2d171f2b-c103-42d2-b1a4-8e954bbceaef</td>\n",
       "      <td>POLYGON ((927.1242390329007 30.31084096671428,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     image_name classification  \\\n",
       "0  midwest-flooding_00000308_post_disaster.json      no-damage   \n",
       "1  midwest-flooding_00000308_post_disaster.json      no-damage   \n",
       "2  midwest-flooding_00000308_post_disaster.json      no-damage   \n",
       "3  midwest-flooding_00000308_post_disaster.json      no-damage   \n",
       "4  midwest-flooding_00000308_post_disaster.json      no-damage   \n",
       "\n",
       "                                    uid  \\\n",
       "0  3350c4e6-e7dc-4313-8b23-59233a6e2078   \n",
       "1  4ac81fae-312a-4050-bd41-92f677311b09   \n",
       "2  bcfa6989-a2b4-4aa6-a1f9-6adc62301b6c   \n",
       "3  497560fe-6da5-4826-a443-cd76fa4f2f86   \n",
       "4  2d171f2b-c103-42d2-b1a4-8e954bbceaef   \n",
       "\n",
       "                                             polygon  \n",
       "0  POLYGON ((319.9690811897951 118.8051167728774,...  \n",
       "1  POLYGON ((448.3688195265795 92.6786134661785, ...  \n",
       "2  POLYGON ((862.4316509232316 13.3651563899852, ...  \n",
       "3  POLYGON ((898.5940151494626 38.91158143295991,...  \n",
       "4  POLYGON ((927.1242390329007 30.31084096671428,...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restrict image to bounding box area and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tracking the scale of all the buildings so we can decide what to scale to \n",
    "width = []\n",
    "height = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_building(name, uid, polygon, file_path, folder): \n",
    "    # Extract the point values that define the perimeter of the polygon\n",
    "    polygon = shapely.wkt.loads(polygon)\n",
    "    x, y = polygon.exterior.coords.xy\n",
    "\n",
    "    bbox = {\n",
    "        'x_min': round(min(x.tolist())), \n",
    "        'x_max': round(max(x.tolist())), \n",
    "        'y_min': round(min(y.tolist())), \n",
    "        'y_max': round(max(y.tolist()))\n",
    "    }\n",
    "\n",
    "    image = cv2.imread(folder + \"/images/\" + name.split(\".json\")[0] + \".png\")\n",
    "    cut_image = Image.fromarray(image[bbox['y_min']:bbox['y_max'], bbox['x_min']:bbox['x_max']])\n",
    "\n",
    "    # check to make sure image isn't cut out of a missing satelitte peice \n",
    "\n",
    "    avg_color_per_row = np.average(cut_image, axis=0)\n",
    "    avg_color = np.average(avg_color_per_row, axis=0)\n",
    "\n",
    "    if avg_color[0] > 10 and avg_color[1] > 10 and avg_color[2] > 10: \n",
    "        \n",
    "        # tracking sizes for later scaling\n",
    "        width.append(bbox['x_max'] - bbox['x_min'])\n",
    "        height.append(bbox['y_max'] - bbox['y_min'])\n",
    "\n",
    "        # to visualize exported image\n",
    "        # display(cut_image)\n",
    "        \n",
    "        # to export image \n",
    "        cut_image.save(file_path + uid + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing to make sure function works correctly \n",
    "# val = 40\n",
    "# export_building(df.loc[val]['image_name'], df.loc[val]['uid'], df.loc[val]['polygon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162787/162787 [1:01:36<00:00, 44.04it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(0, len(df))): \n",
    "    export_building(df.loc[i]['image_name'], df.loc[i]['uid'], df.loc[i]['polygon'], 'classification_images/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average pixel height is 35 pixels.\n",
      "Average pixel width is 35 pixels.\n"
     ]
    }
   ],
   "source": [
    "# determine what we should scale data to \n",
    "print(\"Average pixel height is \" + str(round(sum(height) / len(height))) + \" pixels.\")\n",
    "print(\"Average pixel width is \" + str(round(sum(width) / len(width))) + \" pixels.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export labels for dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset to be used in training contains 162698 images.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "no-damage        117346\n",
       "minor-damage      14976\n",
       "major-damage      14159\n",
       "destroyed         13225\n",
       "un-classified      2992\n",
       "Name: classification, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all the successful uid's for training data \n",
    "dir_path = \"classification_images/\"\n",
    "success_uids = os.listdir(dir_path)\n",
    "print(\"The dataset to be used in training contains \" + str(len(success_uids)) + \" images.\")\n",
    "\n",
    "su = [x.split('.png')[0] for x in success_uids]\n",
    "success_df = df[df['uid'].isin(su)]\n",
    "success_df.to_csv('training_data.csv', index=None)\n",
    "\n",
    "success_df['classification'].value_counts() "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete dataset building for validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1866/1866 [01:25<00:00, 21.77it/s]\n",
      "100%|██████████| 54392/54392 [20:36<00:00, 44.00it/s]\n"
     ]
    }
   ],
   "source": [
    "dir_path = \"hold/labels/\"\n",
    "valid_labels = os.listdir(dir_path)\n",
    "\n",
    "df = find_building_dataset(dir_path, valid_labels)\n",
    "\n",
    "for i in tqdm(range(0, len(df))): \n",
    "    export_building(df.loc[i]['image_name'], df.loc[i]['uid'], df.loc[i]['polygon'], 'holdout_images/', 'hold')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset to be used in validation contains 54307 images.\n"
     ]
    }
   ],
   "source": [
    "# get all the successful uid's for training data \n",
    "dir_path = \"holdout_images/\"\n",
    "success_uids = os.listdir(dir_path)\n",
    "print(\"The dataset to be used in validation contains \" + str(len(success_uids)) + \" images.\")\n",
    "\n",
    "su = [x.split('.png')[0] for x in success_uids]\n",
    "success_df = df[df['uid'].isin(su)]\n",
    "success_df.to_csv('validation_data.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1866/1866 [01:25<00:00, 21.83it/s]\n",
      "100%|██████████| 54862/54862 [20:31<00:00, 44.55it/s]\n"
     ]
    }
   ],
   "source": [
    "dir_path = \"test/labels/\"\n",
    "testing_labels = os.listdir(dir_path)\n",
    "\n",
    "df = find_building_dataset(dir_path, testing_labels)\n",
    "\n",
    "for i in tqdm(range(0, len(df))): \n",
    "    export_building(df.loc[i]['image_name'], df.loc[i]['uid'], df.loc[i]['polygon'], 'testing_images/', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset to be used in testing contains 54842 images.\n"
     ]
    }
   ],
   "source": [
    "# get all the successful uid's for training data \n",
    "dir_path = \"testing_images/\"\n",
    "success_uids = os.listdir(dir_path)\n",
    "print(\"The dataset to be used in testing contains \" + str(len(success_uids)) + \" images.\")\n",
    "\n",
    "su = [x.split('.png')[0] for x in success_uids]\n",
    "success_df = df[df['uid'].isin(su)]\n",
    "success_df.to_csv('testing_data.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average pixel height (training&hold&test) is 35 pixels.\n",
      "Average pixel width (training&hold&test) is 35 pixels.\n"
     ]
    }
   ],
   "source": [
    "# determine what we should scale data to \n",
    "print(\"Average pixel height (training&hold&test) is \" + str(round(sum(height) / len(height))) + \" pixels.\")\n",
    "print(\"Average pixel width (training&hold&test) is \" + str(round(sum(width) / len(width))) + \" pixels.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>classification</th>\n",
       "      <th>uid</th>\n",
       "      <th>polygon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hurricane-harvey_00000037_post_disaster.json</td>\n",
       "      <td>major-damage</td>\n",
       "      <td>5b3cc30b-0144-484d-8132-b6dd145f5b14</td>\n",
       "      <td>POLYGON ((99.9995775966231 770.3191669041304, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hurricane-harvey_00000037_post_disaster.json</td>\n",
       "      <td>destroyed</td>\n",
       "      <td>ff5b6760-fcc4-4da6-802f-8b8cccbd2438</td>\n",
       "      <td>POLYGON ((-4.580597812984772e-06 662.348436749...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>socal-fire_00000753_post_disaster.json</td>\n",
       "      <td>no-damage</td>\n",
       "      <td>7f095106-efeb-4a69-9c5e-212fbdffe691</td>\n",
       "      <td>POLYGON ((16.81967734972283 339.0362917135125,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>socal-fire_00000753_post_disaster.json</td>\n",
       "      <td>no-damage</td>\n",
       "      <td>2484b94c-a406-4314-b69d-1e15e274281f</td>\n",
       "      <td>POLYGON ((-5.539019670407656e-07 355.604034808...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>socal-fire_00000753_post_disaster.json</td>\n",
       "      <td>no-damage</td>\n",
       "      <td>be68c2c5-0e18-4896-8177-2994ff3631db</td>\n",
       "      <td>POLYGON ((17.49449341888473 391.3798187193235,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     image_name classification  \\\n",
       "0  hurricane-harvey_00000037_post_disaster.json   major-damage   \n",
       "1  hurricane-harvey_00000037_post_disaster.json      destroyed   \n",
       "2        socal-fire_00000753_post_disaster.json      no-damage   \n",
       "3        socal-fire_00000753_post_disaster.json      no-damage   \n",
       "4        socal-fire_00000753_post_disaster.json      no-damage   \n",
       "\n",
       "                                    uid  \\\n",
       "0  5b3cc30b-0144-484d-8132-b6dd145f5b14   \n",
       "1  ff5b6760-fcc4-4da6-802f-8b8cccbd2438   \n",
       "2  7f095106-efeb-4a69-9c5e-212fbdffe691   \n",
       "3  2484b94c-a406-4314-b69d-1e15e274281f   \n",
       "4  be68c2c5-0e18-4896-8177-2994ff3631db   \n",
       "\n",
       "                                             polygon  \n",
       "0  POLYGON ((99.9995775966231 770.3191669041304, ...  \n",
       "1  POLYGON ((-4.580597812984772e-06 662.348436749...  \n",
       "2  POLYGON ((16.81967734972283 339.0362917135125,...  \n",
       "3  POLYGON ((-5.539019670407656e-07 355.604034808...  \n",
       "4  POLYGON ((17.49449341888473 391.3798187193235,...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_venv",
   "language": "python",
   "name": "my_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
