{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f68b60a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-23 11:58:41.396530: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-23 11:58:41.508795: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-23 11:58:41.515387: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-23 11:58:43.346262: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from keras_unet_collection import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d8a1ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "from keras.models import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59a6ccb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = \"./train/images/\"\n",
    "MASK_PATH = \"./train/gt/\"\n",
    "READ_SIZE = (512, 512)\n",
    "INPUT_SIZE = (512, 512, 3)\n",
    "BATCH_SIZE = 32\n",
    "VAL_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed828299",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(img):\n",
    "    return img/255\n",
    "\n",
    "def process_mask(img):\n",
    "    mask = img.astype(np.float32)\n",
    "    mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "    return mask\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    return (2. * intersection + smooth) / (K.sum(K.square(y_true),-1) + K.sum(K.square(y_pred),-1) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1-dice_coef(y_true, y_pred)\n",
    "\n",
    "def IoU_coeff(y_true, y_pred):\n",
    "    axes = (1,2) \n",
    "    intersection = tf.keras.backend.sum(tf.math.abs(y_pred * y_true), axis=axes) \n",
    "    mask = tf.keras.backend.sum(tf.math.abs(y_true), axis=axes) + tf.keras.backend.sum(tf.math.abs(y_pred), axis=axes)\n",
    "    union = mask - intersection\n",
    "    smooth = .001\n",
    "    iou = (intersection + smooth) / (union + smooth)\n",
    "    return iou\n",
    "\n",
    "checkpoint_filepath = 'unet-1{epoch:02d}.hdf5'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='loss',\n",
    "    mode='min',\n",
    "    save_freq='epoch',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c57c8886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 576 images belonging to 1 classes.\n",
      "Found 144 images belonging to 1 classes.\n",
      "Found 576 images belonging to 1 classes.\n",
      "Found 144 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "image_data = ImageDataGenerator(preprocessing_function=preprocess_input ,validation_split=VAL_SPLIT)\n",
    "mask_data = ImageDataGenerator(preprocessing_function=process_mask, validation_split=VAL_SPLIT)\n",
    "\n",
    "image_gen = image_data.flow_from_directory(IMAGE_PATH, target_size=READ_SIZE, class_mode=None, \n",
    "                                           batch_size=BATCH_SIZE, shuffle=False, subset='training')\n",
    "val_image_gen = image_data.flow_from_directory(IMAGE_PATH, target_size=READ_SIZE, class_mode=None, \n",
    "                                           batch_size=BATCH_SIZE, shuffle=False, subset='validation')\n",
    "mask_gen = image_data.flow_from_directory(MASK_PATH, target_size=READ_SIZE, class_mode=None, \n",
    "                                          batch_size=BATCH_SIZE, shuffle=False, subset='training')\n",
    "val_mask_gen = image_data.flow_from_directory(MASK_PATH, target_size=READ_SIZE, class_mode=None, \n",
    "                                          batch_size=BATCH_SIZE, shuffle=False, subset='validation')\n",
    "\n",
    "train_generator = zip(image_gen, mask_gen)\n",
    "val_generator = zip(val_image_gen, val_mask_gen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ad28ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.att_unet_2d(INPUT_SIZE, filter_num=[64, 128, 256, 512, 1024], n_labels=1, \n",
    "                           stack_num_down=2, stack_num_up=2, activation='ReLU', \n",
    "                           atten_activation='ReLU', attention='add', output_activation='Sigmoid', \n",
    "                           batch_norm=True, pool=False, unpool=False, \n",
    "                           backbone='VGG16', weights='imagenet', \n",
    "                           freeze_backbone=True, freeze_batch_norm=True, \n",
    "                           name='attunet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76de81a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(1e-3, decay=1e-6), loss=dice_coef_loss, metrics=[dice_coef, IoU_coeff])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b1cf73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-23 19:56:17.086939: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - ETA: 0s - loss: 0.0165 - dice_coef: 0.9835 - IoU_coeff: 0.3576  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-23 20:33:22.061682: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 2355s 131s/step - loss: 0.0165 - dice_coef: 0.9835 - IoU_coeff: 0.3576 - val_loss: 0.0282 - val_dice_coef: 0.9718 - val_IoU_coeff: 0.3853\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 2316s 129s/step - loss: 0.0134 - dice_coef: 0.9866 - IoU_coeff: 0.3636 - val_loss: 0.0385 - val_dice_coef: 0.9615 - val_IoU_coeff: 0.3612\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 2336s 130s/step - loss: 0.0118 - dice_coef: 0.9882 - IoU_coeff: 0.3698 - val_loss: 0.0522 - val_dice_coef: 0.9478 - val_IoU_coeff: 0.3344\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 2327s 130s/step - loss: 0.0117 - dice_coef: 0.9883 - IoU_coeff: 0.3734 - val_loss: 0.0590 - val_dice_coef: 0.9410 - val_IoU_coeff: 0.3165\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 2343s 131s/step - loss: 0.0095 - dice_coef: 0.9905 - IoU_coeff: 0.3837 - val_loss: 0.0567 - val_dice_coef: 0.9433 - val_IoU_coeff: 0.3247\n",
      "Epoch 6/10\n",
      "17/18 [===========================>..] - ETA: 2:02 - loss: 0.0070 - dice_coef: 0.9930 - IoU_coeff: 0.3785"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator, steps_per_epoch = image_gen.samples // BATCH_SIZE, \n",
    "                    validation_data = val_generator, validation_steps = val_image_gen.samples // BATCH_SIZE, \n",
    "                    epochs=10, callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "179462d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "model_json = model.to_json()\n",
    "with open(\"kunetmodel-2.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"kunetmodel.h5\")\n",
    "with open('./kunetHistory-1', 'wb') as file_pi:\n",
    "    pickle.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03cb43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Trained Model for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763c1c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open('kunetmodel.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"unet-101.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0d3d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile as tiff\n",
    "img = val_gen.next()[0]\n",
    "tiff.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c68b784",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = model.predict(np.array([img]))\n",
    "tiff.imshow(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff29fc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boundingbox(mask):\n",
    "    mask = (mask[0]).astype(int)\n",
    "    ret, thresh = cv2.threshold((mask*255).astype(np.uint8), 127, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # Get bounding boxes for each contour\n",
    "    bounding_boxes = []\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        bounding_boxes.append((x, y, w, h))\n",
    "\n",
    "    # Print the bounding boxes\n",
    "    return bounding_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3375641",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img * 255\n",
    "for box in boxes:\n",
    "    x,y,w,h = box\n",
    "    cv2.rectangle(img, (x,y), (x+w,y+h), (0,255,0), 1)\n",
    "tiff.imshow(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
