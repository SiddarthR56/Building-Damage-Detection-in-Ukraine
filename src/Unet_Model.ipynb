{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "045260f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'skimage'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mskimage\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mio\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mskimage\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransform\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtrans\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'skimage'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7108a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = \"./timages/\"\n",
    "MASK_PATH = \"./masks/\"\n",
    "READ_SIZE = (512, 512)\n",
    "INPUT_SIZE = (512, 512, 3)\n",
    "BATCH_SIZE = 32\n",
    "VAL_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f30478e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcs for metrics, preprocessing\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    return (2. * intersection + smooth) / (K.sum(K.square(y_true),-1) + K.sum(K.square(y_pred),-1) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1-dice_coef(y_true, y_pred)\n",
    "\n",
    "def IoU_coeff(y_true, y_pred):\n",
    "    axes = (1,2) \n",
    "    intersection = tf.keras.backend.sum(tf.math.abs(y_pred * y_true), axis=axes) \n",
    "    mask = tf.keras.backend.sum(tf.math.abs(y_true), axis=axes) + tf.keras.backend.sum(tf.math.abs(y_pred), axis=axes)\n",
    "    union = mask - intersection\n",
    "    smooth = .001\n",
    "    iou = (intersection + smooth) / (union + smooth)\n",
    "    return iou\n",
    "\n",
    "def process_mask(img):\n",
    "    mask = img.astype(np.float32)\n",
    "    mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3bb063",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Datagenerator\n",
    "image_data = ImageDataGenerator(validation_split=VAL_SPLIT)\n",
    "mask_data = ImageDataGenerator(preprocessing_function=process_mask, validation_split=VAL_SPLIT)\n",
    "\n",
    "image_gen = image_data.flow_from_directory(IMAGE_PATH, target_size=READ_SIZE, class_mode=None, \n",
    "                                           batch_size=BATCH_SIZE, shuffle=False, subset='training')\n",
    "val_image_gen = image_data.flow_from_directory(IMAGE_PATH, target_size=READ_SIZE, class_mode=None, \n",
    "                                           batch_size=BATCH_SIZE, shuffle=False, subset='validation')\n",
    "mask_gen = image_data.flow_from_directory(MASK_PATH, target_size=READ_SIZE, class_mode=None, \n",
    "                                          batch_size=BATCH_SIZE, shuffle=False, subset='training')\n",
    "val_mask_gen = image_data.flow_from_directory(MASK_PATH, target_size=READ_SIZE, class_mode=None, \n",
    "                                          batch_size=BATCH_SIZE, shuffle=False, subset='validation')\n",
    "\n",
    "train_generator = zip(image_gen, mask_gen)\n",
    "val_generator = zip(val_image_gen, val_mask_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917ab5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Unet Model\n",
    "inputs = Input(INPUT_SIZE)\n",
    "conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "drop4 = Dropout(0.5)(conv4)\n",
    "pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "merge6 = concatenate([drop4,up6], axis = 3)\n",
    "conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "merge7 = concatenate([conv3,up7], axis = 3)\n",
    "conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "merge8 = concatenate([conv2,up8], axis = 3)\n",
    "conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "merge9 = concatenate([conv1,up9], axis = 3)\n",
    "conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "model = Model(inputs, conv10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab89496e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(1e-4, decay=1e-6), loss=dice_coef_loss, metrics=[dice_coef, IoU_coeff])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dc00a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_generator, steps_per_epoch = image_gen.samples // BATCH_SIZE, \n",
    "                    validation_data = val_generator, validation_steps = val_image_gen.samples // BATCH_SIZE, \n",
    "                    epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550baf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Model and training History\n",
    "model_json = model.to_json()\n",
    "with open(\"Unet_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"Unet_model.h5\")\n",
    "\n",
    "with open('/Unet_trainHistory', 'wb') as file_pi:\n",
    "    pickle.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a356215",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('loss')\n",
    "plt.ylabel('val_loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['dice_coef'])\n",
    "plt.plot(history.history['val_dice_coef'])\n",
    "plt.title('dice_coef')\n",
    "plt.ylabel('dice_coef')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "                         \n",
    "plt.plot(history.history['IoU_coeff'])\n",
    "plt.plot(history.history['val_IoU_coeff'])\n",
    "plt.title('iou')\n",
    "plt.ylabel('iou')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434d9b8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75273ec1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f82a6df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f12474",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97050049",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
